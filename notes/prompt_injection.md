**What happened when you tried the prompts?**
ChatGPT was funny. It kind of followed what I said, but it could tell I was doing a lesson, so it didn’t fully give in. It responded to the pirate prompt but didn’t totally abandon the original prompt.

**Why could prompt injection be dangerous?**
It can be dangerous because it takes advantage of how obedient AI is. If someone uses it in the wrong way, the AI could leak sensitive information or do something with serious consequences.
